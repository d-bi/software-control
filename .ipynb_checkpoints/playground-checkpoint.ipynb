{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook containing **software-control** EEG processing pipeline. Goal is a general purpose discrimination system for EEG data, ie. the ability to classify sample EEG traces to a few given categories.\n",
    "\n",
    "*Authors: Dasheng Bi*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data import, preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization, clustering\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# OS\n",
    "import os\n",
    "\n",
    "# Path properties\n",
    "train_root = 'csv_sa_2/'\n",
    "test_root = 'csv_sa_2/'\n",
    "prefix = 'db-rec-'\n",
    "label = ['GO_', 'STOP_']\n",
    "train_number = range(1, 4)\n",
    "# test_number = range(3, 4)\n",
    "suffix = '.csv'\n",
    "\n",
    "# Data properties\n",
    "SAMPLE_FREQ = 256\n",
    "INTERVAL = 0.4\n",
    "# N_COMPONENTS = 4 # raw data\n",
    "N_COMPONENTS = 20 # filtered DTABG components\n",
    "TRAIN_SAMPLES = 60\n",
    "TEST_SAMPLES = 36\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# Audio\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "\n",
    "# Audio Path Properties\n",
    "audio_root = 'sound_2/'\n",
    "audio_prefix = ''\n",
    "audio_suffix = '.wav'\n",
    "\n",
    "# Audio Data Properties\n",
    "AUDIO_SAMPLE_FREQ = 44100\n",
    "AUDIO_EVENT_THRESHOLD_LO = 1\n",
    "AUDIO_EVENT_THRESHOLD_HI = 1000\n",
    "MIN_AUDIO_EVENT_LENGTH = 10000\n",
    "\n",
    "########################################################################\n",
    "# A note on labels: 1 is \"go,\" 0 is \"stop.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading, Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data import, preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization, clustering\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path properties\n",
    "root = 'csv1/'\n",
    "prefix = 'db-rec-'\n",
    "label = ['GO_', 'STOP_']\n",
    "number = range(1, 6)\n",
    "suffix = '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data, Select Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FREQ = 256\n",
    "INTERVAL = 0.5\n",
    "\n",
    "# N_COMPONENTS = 4 # raw data\n",
    "N_COMPONENTS = 20 # filtered DTABG components\n",
    "\n",
    "TRAIN_SAMPLES = 60\n",
    "TEST_SAMPLES = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = root + prefix + label[0] + str(number[0]) + suffix\n",
    "df = pd.read_csv(path)\n",
    "print(df.columns)\n",
    "df = df.drop(columns=df.columns[21:])\n",
    "print(df.columns)\n",
    "df = df.drop(columns=df.columns[0])\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_stack = np.empty((0, int(INTERVAL * SAMPLE_FREQ * N_COMPONENTS)))\n",
    "# print(data_stack)\n",
    "# print(data_stack.shape)\n",
    "for l in label:\n",
    "    for trial in train_number:\n",
    "        path = train_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:]) # drop raw columns\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "\n",
    "        if (df.equals(df.dropna()) == False):\n",
    "            print(\"Dropped NaN: \\n\", np.argwhere(np.isnan(df.values)))\n",
    "            df = df.dropna()  # Drop NaN (blank) datapts.\n",
    "\n",
    "        OFFSET = 1\n",
    "        while OFFSET < 7:\n",
    "            START = int(OFFSET * SAMPLE_FREQ)\n",
    "            END = int(START + SAMPLE_FREQ * INTERVAL)\n",
    "            OFFSET += 0.5\n",
    "\n",
    "            raw = df.iloc[START:END]  # Select by row\n",
    "            raw_vals = raw.values\n",
    "    #         print(np.argwhere(np.isnan(raw_vals)))\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, int(INTERVAL * SAMPLE_FREQ * N_COMPONENTS)))\n",
    "            data_stack = np.concatenate((data_stack, raw_vals), axis=0)\n",
    "#         print(data_stack.shape)\n",
    "df_stack = pd.DataFrame(data_stack)\n",
    "# print(df_stack.head())\n",
    "# num_rows=num_trials; num_cols=num_datapts\n",
    "print(\"data_stack shape: \", data_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(data_stack))) == 0)  # Should be empty\n",
    "\n",
    "# Labels\n",
    "train_labels = [1] * TRAIN_SAMPLES + [0] * TRAIN_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stack = np.empty((0, int(INTERVAL * SAMPLE_FREQ * N_COMPONENTS)))\n",
    "for l in label:\n",
    "    for trial in test_number:\n",
    "        path = test_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:]) # drop raw columns\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "        \n",
    "        if (df.equals(df.dropna()) == False):\n",
    "            print(\"Dropped NaN: \\n\", np.argwhere(np.isnan(df.values)))\n",
    "            df = df.dropna()  # Drop NaN (blank) datapts.\n",
    "\n",
    "        OFFSET = 1\n",
    "        while OFFSET < 7:\n",
    "            START = int(OFFSET * SAMPLE_FREQ)\n",
    "            END = int(START + SAMPLE_FREQ * INTERVAL)\n",
    "            OFFSET += 0.5\n",
    "\n",
    "            raw = df.iloc[START:END]  # Select by row\n",
    "            raw_vals = raw.values\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, int(INTERVAL * SAMPLE_FREQ * N_COMPONENTS)))\n",
    "            test_stack = np.concatenate((test_stack, raw_vals), axis=0)\n",
    "#             print(test_stack.shape)\n",
    "df_test = pd.DataFrame(test_stack)\n",
    "# print(df_stack.head())\n",
    "# num_rows=num_trials; num_cols=num_datapts\n",
    "print(\"test_stack shape: \", test_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(test_stack))) == 0)  # Should be empty\n",
    "\n",
    "# Labels\n",
    "test_labels = [1] * TEST_SAMPLES + [0] * TEST_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Clustering of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(df_columns)\n",
    "\n",
    "tsne_df = pd.DataFrame()\n",
    "\n",
    "# Plot\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:, 0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:, 1]\n",
    "# Labels\n",
    "y = [1] * NUM_SAMPLES[0] + [0] * NUM_SAMPLES[1]\n",
    "tsne_df['y'] = y\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=tsne_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground: Multiple t-SNEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10), constrained_layout=True)\n",
    "spec = gridspec.GridSpec(ncols=5, nrows=5, figure=fig)\n",
    "\n",
    "for niter in range(250, 1500, 250):\n",
    "    for perp in range(10, 55, 10):\n",
    "        # multiple t-SNEs\n",
    "        tsne = TSNE(n_components=2, verbose=1, perplexity=perp, n_iter=niter)\n",
    "        tsne_results = tsne.fit_transform(df_columns)\n",
    "        \n",
    "        tsne_df = pd.DataFrame()\n",
    "        \n",
    "        coord_prefix = 'tsne-2d-'\n",
    "        coord_desc = str(niter) + '-' + str(perp)\n",
    "        x_coord = coord_prefix + coord_desc + '-one'\n",
    "        y_coord = coord_prefix + coord_desc + '-two'\n",
    "        tsne_df[x_coord] = tsne_results[:, 0]\n",
    "        tsne_df[y_coord] = tsne_results[:, 1]\n",
    "\n",
    "        # Labels\n",
    "        y = [1] * NUM_SAMPLES[0] + [0] * NUM_SAMPLES[1]\n",
    "        tsne_df['y'] = y\n",
    "\n",
    "        niter_offset = int((niter-250)/250)\n",
    "        perp_offset = int((perp-10)/10)\n",
    "        fig.add_subplot(spec[niter_offset, perp_offset])\n",
    "        sns.scatterplot(\n",
    "            x=x_coord, y=y_coord,\n",
    "            hue=\"y\",\n",
    "            palette=sns.color_palette(\"hls\", 2),\n",
    "            data=tsne_df,\n",
    "            legend=\"full\",\n",
    "            alpha=0.8,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Clustering of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca_result = pca.fit_transform(df_columns)\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "print('Sum:', sum(pca.explained_variance_ratio_))\n",
    "## Explained variation per principal component: [0.1557712  0.11314638 0.08842925]\n",
    "\n",
    "# Labels\n",
    "y = [1] * NUM_TRAIN_SAMPLES[0] \\\n",
    "    + [2] * NUM_TEST_SAMPLES[0] \\\n",
    "    + [0] * NUM_TRAIN_SAMPLES[1] \\\n",
    "    + [3] * NUM_TEST_SAMPLES[1]\n",
    "\n",
    "# Plot: 3d\n",
    "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=pca_result[:,0], \n",
    "    ys=pca_result[:,1], \n",
    "    zs=pca_result[:,2], \n",
    "    c=y, \n",
    "    cmap='jet',\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.show()\n",
    "\n",
    "# Plot: 2d\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=pca_result[:,0], y=pca_result[:,1],\n",
    "    hue=y,\n",
    "    palette=sns.color_palette(\"hls\", 4),\n",
    "    legend=\"full\",\n",
    "    alpha=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Synchronized Events from Audio/EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_eeg_index(audio_index):\n",
    "    return int(audio_index / AUDIO_SAMPLE_FREQ * SAMPLE_FREQ)\n",
    "\n",
    "END = to_eeg_index(INTERVAL * AUDIO_SAMPLE_FREQ) # Produce training samples of uniform length.\n",
    "df_columns = np.empty((0, int(END * N_COMPONENTS)))\n",
    "data_stack = np.empty((0, END, N_COMPONENTS))\n",
    "\n",
    "NUM_SAMPLES = []\n",
    "\n",
    "for l in label:\n",
    "    print(l)\n",
    "    event_cts = 0\n",
    "    for trial in train_number:\n",
    "        print('####', end=' ')\n",
    "        ### READ AUDIO DATA\n",
    "        audio_path = audio_root + audio_prefix + l + str(trial) + audio_suffix\n",
    "        _, samples = wavfile.read(audio_path)\n",
    "        envelope = np.abs(signal.hilbert(samples))\n",
    "        \n",
    "        ### GET AUDIO EVENTS\n",
    "        events = np.empty((0, 2))\n",
    "        in_event = False\n",
    "        new_event = np.zeros((1, 2))\n",
    "        hi_threshold_check = False\n",
    "        for s in range(len(samples)):\n",
    "            if (not in_event) and (envelope[s] >= AUDIO_EVENT_THRESHOLD_LO):\n",
    "                in_event = True\n",
    "                new_event[0][0] = s\n",
    "            elif (in_event) and (envelope[s] < AUDIO_EVENT_THRESHOLD_LO):\n",
    "                in_event = False\n",
    "                new_event[0][1] = s\n",
    "                event_length = new_event[0][1] - new_event[0][0]\n",
    "                if hi_threshold_check and event_length >= MIN_AUDIO_EVENT_LENGTH:\n",
    "#                     print(new_event[0][1] - new_event[0][0], end=' ') # Verbose Progress bar\n",
    "                    print('*', end='') # Simplified progress bar\n",
    "                    events = np.concatenate((events, new_event), axis=0)\n",
    "                    hi_threshold_check = False\n",
    "            elif (in_event) and (envelope[s] >= AUDIO_EVENT_THRESHOLD_HI):\n",
    "                hi_threshold_check = True\n",
    "\n",
    "        ### READ EEG DATA\n",
    "        cortical_path = train_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(cortical_path)\n",
    "        \n",
    "        \n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:])\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "\n",
    "        ### EXTRACT EEG EVENTS FROM AUDIO EVENTS\n",
    "        cts = 0\n",
    "        for e in events:\n",
    "            cts += 1\n",
    "            event_cts += 1\n",
    "            \n",
    "            START = to_eeg_index(e[0])\n",
    "\n",
    "            raw = df.iloc[START:]\n",
    "            if (raw.equals(raw.dropna()) == False):\n",
    "                # print('Dropped NaN: %s%d, sample %d' %(l, trial, ct))\n",
    "                raw = raw.dropna()\n",
    "            raw = raw.iloc[:END]\n",
    "            raw_vals = raw.values\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, END, N_COMPONENTS)) # Split into N_COMPONENTS channels\n",
    "            data_stack = np.concatenate((data_stack, raw_vals), axis=0)\n",
    "            \n",
    "            df_col = np.reshape(\n",
    "                raw_vals, (1, int(END * N_COMPONENTS))) # One vector of df_stack\n",
    "            df_columns = np.concatenate((df_columns, df_col), axis=0)\n",
    "            \n",
    "        print('*' + str(cts), end=' ') # Progress bar\n",
    "        \n",
    "    NUM_SAMPLES = NUM_SAMPLES + [event_cts]\n",
    "    print('\\n')\n",
    "\n",
    "df_stack = pd.DataFrame(df_columns) # Will only work when data is combined.\n",
    "# print(df_stack.head())\n",
    "print(\"data_stack shape: \", data_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(data_stack))) == 0)  # Should be empty\n",
    "\n",
    "# Labels: 1=GO, 0=STOP\n",
    "data_labels = [1] * NUM_SAMPLES[0] + [0] * NUM_SAMPLES[1]\n",
    "print(NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_SAMPLES = [150, 150]\n",
    "NUM_TEST_SAMPLES = [36, 56]\n",
    "\n",
    "# train_df = df_stack.iloc[np.r_[\n",
    "#     0:NUM_TRAIN_SAMPLES[0], \n",
    "#     NUM_SAMPLES[0]:NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]]]\n",
    "# test_df = df_stack.iloc[np.r_[\n",
    "#     NUM_TRAIN_SAMPLES[0]:NUM_SAMPLES[0],\n",
    "#     NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]:NUM_SAMPLES[0]+NUM_SAMPLES[1]]]\n",
    "# train_stack = train_df.values\n",
    "# test_stack = test_df.values\n",
    "\n",
    "train_stack = data_stack[np.r_[\n",
    "    0:NUM_TRAIN_SAMPLES[0], \n",
    "    NUM_SAMPLES[0]:NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]], :, :]\n",
    "test_stack = data_stack[np.r_[\n",
    "    NUM_TRAIN_SAMPLES[0]:NUM_TRAIN_SAMPLES[0]+NUM_TEST_SAMPLES[0],\n",
    "    NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]:NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]+NUM_TEST_SAMPLES[1]], :, :]\n",
    "print(train_stack.shape, test_stack.shape)\n",
    "\n",
    "train_data = np.split(train_stack, N_COMPONENTS, axis=2)\n",
    "test_data = np.split(test_stack, N_COMPONENTS, axis=2)\n",
    "print(len(train_data), train_data[0].shape)\n",
    "print(len(test_data), test_data[0].shape)\n",
    "\n",
    "# Labels: 1=GO, 0=STOP\n",
    "train_labels = np.asarray([1] * NUM_TRAIN_SAMPLES[0] + [0] * NUM_TRAIN_SAMPLES[1])\n",
    "test_labels = np.asarray([1] * NUM_TEST_SAMPLES[0] + [0] * NUM_TEST_SAMPLES[1])\n",
    "print(train_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Plot Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = audio_root + audio_prefix + label[1] + str(1) + audio_suffix\n",
    "print(audio_path)\n",
    "sample_rate, samples = wavfile.read(audio_path)\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(samples[:], )\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Events from Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_EVENT_THRESHOLD_LO = 1\n",
    "AUDIO_EVENT_THRESHOLD_HI = 1000\n",
    "AUDIO_PLT_LEFT, AUDIO_PLT_RIGHT = 0, len(envelope)\n",
    "envelope = np.abs(signal.hilbert(samples))\n",
    "threshold_lo = np.ones(len(envelope)) * AUDIO_EVENT_THRESHOLD_LO\n",
    "threshold_hi = np.ones(len(envelope)) * AUDIO_EVENT_THRESHOLD_HI\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.xlabel('Sample Coordinate'); plt.ylabel('Amplitude')\n",
    "plt.plot(samples[AUDIO_PLT_LEFT:AUDIO_PLT_RIGHT], label='raw')\n",
    "plt.plot(envelope[AUDIO_PLT_LEFT:AUDIO_PLT_RIGHT], label='envelope')\n",
    "plt.plot(threshold_lo[AUDIO_PLT_LEFT:AUDIO_PLT_RIGHT], label='threshold_lo')\n",
    "plt.plot(threshold_hi[AUDIO_PLT_LEFT:AUDIO_PLT_RIGHT], label='threshold_hi')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "events = np.empty((0, 2))\n",
    "in_event = False\n",
    "new_event = np.zeros((1, 2))\n",
    "hi_threshold_check = False\n",
    "\n",
    "for s in range(len(samples)):\n",
    "    if (not in_event) and (envelope[s] >= AUDIO_EVENT_THRESHOLD_LO):\n",
    "        in_event = True\n",
    "        new_event[0][0] = s\n",
    "    elif (in_event) and (envelope[s] < AUDIO_EVENT_THRESHOLD_LO):\n",
    "        in_event = False\n",
    "        new_event[0][1] = s\n",
    "        if hi_threshold_check:\n",
    "            events = np.concatenate((events, new_event), axis=0)\n",
    "            hi_threshold_check = False\n",
    "    elif (in_event) and (envelope[s] >= AUDIO_EVENT_THRESHOLD_HI):\n",
    "        hi_threshold_check = True\n",
    "\n",
    "print(events, len(events))\n",
    "\n",
    "for e in events:\n",
    "    print(e[1]-e[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference via KNN in PCA Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Sample into PCA Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_pca(raw_eeg, pca_components):\n",
    "    \"\"\"\n",
    "    Embeds RAW_EEG into the PCA representation space given by PCA_COMPONENTS\n",
    "    \"\"\"\n",
    "    return np.dot(pca_components, raw_eeg.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack_pca = embed_pca(train_stack, pca.components_)\n",
    "print(train_stack_pca.shape)\n",
    "test_stack_pca = embed_pca(test_stack, pca.components_)\n",
    "print(test_stack_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground: Embedding one sample into PCA Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure for obtaining one sample's representation in PCA space\n",
    "sample = data_stack[0,:]\n",
    "print(sample.shape)\n",
    "sample_rep = np.dot(pca_components, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground: Test Different k-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 51)\n",
    "scores_list = []\n",
    "TEST_TO_TRAIN_WEIGHT = 5\n",
    "total_stack_pca = np.concatenate(\n",
    "    (np.tile(test_stack_pca,\n",
    "             (TEST_TO_TRAIN_WEIGHT, 1)),\n",
    "     train_stack_pca))\n",
    "total_labels = np.concatenate(\n",
    "    (np.tile(test_labels,\n",
    "             (TEST_TO_TRAIN_WEIGHT)),\n",
    "     train_labels))\n",
    "print(total_stack_pca.shape)\n",
    "print(total_labels.shape)\n",
    "for k_val in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "    knn.fit(train_stack_pca, train_labels)\n",
    "    knn_predict = knn.predict(test_stack_pca)\n",
    "    scores_list.append(metrics.accuracy_score(test_labels, knn_predict))\n",
    "\n",
    "print('Maximum accuracy is %f' % (np.amax(scores_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot KNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=k_range, y=scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data to tf.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read into Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = 'csvc/'\n",
    "test_root = 'csvc/'\n",
    "train_number = range(1, 6)\n",
    "test_number = range(6, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stack = np.empty((0, int(INTERVAL * SAMPLE_FREQ), N_COMPONENTS))\n",
    "# print(data_stack.shape)\n",
    "\n",
    "for l in label:\n",
    "    for trial in train_number:\n",
    "        path = train_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:]) # drop raw columns\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "        \n",
    "#         print(df.shape)\n",
    "\n",
    "        if (df.equals(df.dropna()) == False):\n",
    "            print(\"Dropped NaN: \\n\", np.argwhere(np.isnan(df.values)))\n",
    "            df = df.dropna()  # Drop NaN (blank) datapts.\n",
    "\n",
    "        OFFSET = 1\n",
    "        while OFFSET < 7:\n",
    "            START = int(OFFSET * SAMPLE_FREQ)\n",
    "            END = int(START + SAMPLE_FREQ * INTERVAL)\n",
    "            OFFSET += 0.5\n",
    "\n",
    "            raw = df.iloc[START:END]  # Select by row\n",
    "            raw_vals = raw.values\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, int(INTERVAL * SAMPLE_FREQ), N_COMPONENTS))\n",
    "            data_stack = np.concatenate((data_stack, raw_vals), axis=0)\n",
    "#         print(data_stack.shape)\n",
    "        \n",
    "print(\"data_stack shape: \", data_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(data_stack))) == 0)  # Should be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stack = np.empty((0, int(INTERVAL * SAMPLE_FREQ), N_COMPONENTS))\n",
    "for l in label:\n",
    "    for trial in test_number:\n",
    "        path = test_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:]) # drop raw columns\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "        \n",
    "        if (df.equals(df.dropna()) == False):\n",
    "            print(\"Dropped NaN: \\n\", np.argwhere(np.isnan(df.values)))\n",
    "            df = df.dropna()  # Drop NaN (blank) datapts.\n",
    "\n",
    "        OFFSET = 1\n",
    "        while OFFSET < 7:\n",
    "            START = int(OFFSET * SAMPLE_FREQ)\n",
    "            END = int(START + SAMPLE_FREQ * INTERVAL)\n",
    "            OFFSET += 0.5\n",
    "\n",
    "            raw = df.iloc[START:END]  # Select by row\n",
    "            raw_vals = raw.values\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, int(INTERVAL * SAMPLE_FREQ), N_COMPONENTS))\n",
    "            test_stack = np.concatenate((test_stack, raw_vals), axis=0)\n",
    "#             print(test_stack.shape)\n",
    "# df_test = pd.DataFrame(test_stack)\n",
    "# print(df_stack.head())\n",
    "# num_rows=num_trials; num_cols=num_datapts\n",
    "print(\"test_stack shape: \", test_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(test_stack))) == 0)  # Should be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "train_labels = np.concatenate(\n",
    "    (np.tile([0, 1], (NUM_TRAIN_SAMPLES[0], 1)), # GO\n",
    "     np.tile([1, 0], (NUM_TRAIN_SAMPLES[1], 1))) # STOP\n",
    ")\n",
    "test_labels = np.concatenate(\n",
    "    (np.tile([0, 1], (NUM_TEST_SAMPLES[0], 1)), # GO\n",
    "     np.tile([1, 0], (NUM_TEST_SAMPLES[1], 1))) # STOP\n",
    ")\n",
    "# [0 1]=GO, [1 0]=STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tf.data.Dataset from tensor slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DATASET_SIZE = NUM_TRAIN_SAMPLES[0] + NUM_TRAIN_SAMPLES[1]\n",
    "TRAIN_SIZE = int(FULL_DATASET_SIZE * 0.8)\n",
    "VALIDATION_SIZE = int(FULL_DATASET_SIZE * 0.2)\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "VALIDATION_BATCH_SIZE = 1\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_stack, train_labels)\n",
    ").shuffle(FULL_DATASET_SIZE)\n",
    "\n",
    "train_dataset = full_dataset.take(TRAIN_SIZE).batch(TRAIN_BATCH_SIZE)\n",
    "validation_dataset = full_dataset.skip(TRAIN_SIZE).take(VALIDATION_SIZE).batch(VALIDATION_BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_stack, test_labels))\n",
    "TEST_SHUFFLE_BUFFER = NUM_TEST_SAMPLES[0] + NUM_TEST_SAMPLES[1]\n",
    "TEST_BATCH_SIZE = 1\n",
    "test_dataset = test_dataset.shuffle(TEST_SHUFFLE_BUFFER).batch(TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset, validation_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Basic Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (int(SAMPLE_FREQ * INTERVAL), N_COMPONENTS, 1)\n",
    "raw_shape = (2040, 1)\n",
    "inputs = keras.Input(shape=raw_shape)\n",
    "# A proposed architecture is to use recurrent first to \"summarize,\"\n",
    "    # No need for embedding layer in recurrent subnetwork?\n",
    "# then use convolutional to classify.\n",
    "\n",
    "# reshape\n",
    "reshape = layers.Reshape((int(SAMPLE_FREQ * INTERVAL), N_COMPONENTS, 1), input_shape=raw_shape)\n",
    "first_conv = layers.Conv2D(16, 3, activation='relu')\n",
    "first_pool = layers.MaxPool2D(pool_size=(2, 1))\n",
    "second_conv = layers.Conv2D(32, 3, activation='relu')\n",
    "second_pool = layers.MaxPool2D(pool_size=(2, 1))\n",
    "third_conv = layers.Conv2D(64, 3, activation='relu')\n",
    "flattener = layers.Flatten()\n",
    "first_dense = layers.Dense(64, activation='relu')\n",
    "second_dense = layers.Dense(16, activation='relu')\n",
    "third_dense = layers.Dense(2)\n",
    "\n",
    "outputs = third_dense(\n",
    "    second_dense(first_dense(\n",
    "        flattener(\n",
    "            third_conv(\n",
    "                second_pool(second_conv(\n",
    "                    first_pool(first_conv(reshape(inputs))))))))))\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='simple_conv')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Basic Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (int(SAMPLE_FREQ * INTERVAL), N_COMPONENTS)\n",
    "raw_shape = (2040,1)\n",
    "inputs = keras.Input(shape=raw_shape)\n",
    "\n",
    "reshape = layers.Reshape(input_shape, input_shape=raw_shape)\n",
    "recurr_layer = layers.LSTM(64, dropout=0.1, recurrent_dropout=0.1)\n",
    "first_dense = layers.Dense(64, activation='sigmoid')\n",
    "result_dense = layers.Dense(2, activation='sigmoid')\n",
    "\n",
    "outputs = result_dense(\n",
    "        first_dense(\n",
    "            recurr_layer(reshape(inputs))))\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='simple_lstm')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Multi-Channel Recurrent-->Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_ch_input_shape = (END, 1)\n",
    "LSTM_REDUCE_DIM = 64\n",
    "\n",
    "channel_inputs, recurr_layers = [], []\n",
    "for ch in range(N_COMPONENTS):\n",
    "    channel_inputs = channel_inputs + [keras.Input(shape=sg_ch_input_shape)]\n",
    "    recurr_layers = recurr_layers + [layers.LSTM(LSTM_REDUCE_DIM)(channel_inputs[ch])]\n",
    "    \n",
    "recurr_outs = layers.concatenate(recurr_layers)\n",
    "first_dense = layers.Dense(64, activation='tanh')(recurr_outs)\n",
    "dropout = layers.Dropout(0.1)(first_dense)\n",
    "output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "model = keras.Model(inputs=channel_inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'multi-channel_recurrent.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Recurrent-->Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_ch_input_shape = (END, 1)\n",
    "LSTM_REDUCE_DIM = N_COMPONENTS\n",
    "\n",
    "channel_inputs, recurr_layers = [], []\n",
    "for ch in range(N_COMPONENTS):\n",
    "    channel_inputs = channel_inputs + [keras.Input(shape=sg_ch_input_shape)]\n",
    "    recurr_layers = recurr_layers + [layers.LSTM(LSTM_REDUCE_DIM)(channel_inputs[ch])]\n",
    "    \n",
    "recurr_outs = layers.concatenate(recurr_layers) # reshape?\n",
    "first_conv = layers.Conv2D(16, 3, activation='relu')(recurr_outs) \n",
    "first_pool = layers.MaxPool2D(pool_size=(2, 1))\n",
    "second_conv = layers.Conv2D(32, 3, activation='relu')\n",
    "second_pool = layers.MaxPool2D(pool_size=(2, 1))\n",
    "first_dense = layers.Dense(64, activation='tanh')(recurr_outs)\n",
    "dropout = layers.Dropout(0.1)(first_dense)\n",
    "output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "model = keras.Model(inputs=channel_inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split-Channel Recurrent-Convolutional Neural Network (SpecTransformerNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw inputs (4 signals)\n",
    "# spectrogram from each EEG channel (4 spectrograms)\n",
    "# multi-channel recurrent net (transformer?)\n",
    "# feature image with 4 \"spatial channels\" (2d * 4)\n",
    "# ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=10, verbose=1, validation_data=validation_dataset) # with tf.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, train_labels, batch_size=8, epochs=30, validation_split=0.2, verbose=1) # split channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = model.predict(test_data)\n",
    "round_test_out = list(map(np.round, np.concatenate(test_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "sns.scatterplot(x=range(len(round_test_out)),\n",
    "                y=round_test_out,\n",
    "                hue=test_labels,\n",
    "                alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = 'models/'\n",
    "model_name = 'multi-channel_recurrent'\n",
    "model_suffix = '.h5'\n",
    "model_path = model_root + model_name + model_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "613.2px",
    "left": "43px",
    "top": "110.8px",
    "width": "259.79px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 378.17572800000005,
   "position": {
    "height": "398.898px",
    "left": "798.364px",
    "right": "20px",
    "top": "20px",
    "width": "583.352px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
