{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook containing **software-control** EEG processing pipeline. Goal is a general purpose discrimination system for EEG data, ie. the ability to classify sample EEG traces to a few given categories.\n",
    "\n",
    "*Authors: Dasheng Bi*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data import, preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# # Visualization, clustering\n",
    "import seaborn as sns\n",
    "# import matplotlib.gridspec as gridspec\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "# plt.ioff()\n",
    "\n",
    "# # KNN\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn import metrics\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# OS, Control\n",
    "import os\n",
    "# import sys\n",
    "\n",
    "# Path properties\n",
    "train_root = 'csv_sa_2/'\n",
    "test_root = 'csv_sa_2/'\n",
    "prefix = 'db-rec-'\n",
    "label = ['GO_', 'STOP_']\n",
    "train_number = range(1, 4)\n",
    "# test_number = range(3, 4)\n",
    "suffix = '.csv'\n",
    "\n",
    "# Data properties\n",
    "SAMPLE_FREQ = 256\n",
    "INTERVAL = 0.4\n",
    "N_COMPONENTS = 4 # raw data\n",
    "# N_COMPONENTS = 20 # filtered DTABG components\n",
    "TRAIN_SAMPLES = 60\n",
    "TEST_SAMPLES = 36\n",
    "\n",
    "# Spectrogram\n",
    "N_SPECT_FREQS, N_SPECT_TIMES = 33, 39\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# Audio\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "\n",
    "# Audio Path Properties\n",
    "audio_root = 'sound_2/'\n",
    "audio_prefix = ''\n",
    "audio_suffix = '.wav'\n",
    "\n",
    "# Audio Data Properties\n",
    "AUDIO_SAMPLE_FREQ = 44100\n",
    "AUDIO_EVENT_THRESHOLD_LO = 1\n",
    "AUDIO_EVENT_THRESHOLD_HI = 1000\n",
    "MIN_AUDIO_EVENT_LENGTH = 10000\n",
    "\n",
    "########################################################################\n",
    "# A note on labels: 1 is \"go,\" 0 is \"stop.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data; Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data import, preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization, clustering\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path properties\n",
    "root = 'csv1/'\n",
    "prefix = 'db-rec-'\n",
    "label = ['GO_', 'STOP_']\n",
    "number = range(1, 6)\n",
    "suffix = '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data, Select Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FREQ = 256\n",
    "INTERVAL = 0.5\n",
    "\n",
    "# N_COMPONENTS = 4 # raw data\n",
    "N_COMPONENTS = 20 # filtered DTABG components\n",
    "\n",
    "TRAIN_SAMPLES = 60\n",
    "TEST_SAMPLES = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = root + prefix + label[0] + str(number[0]) + suffix\n",
    "df = pd.read_csv(path)\n",
    "print(df.columns)\n",
    "df = df.drop(columns=df.columns[21:])\n",
    "print(df.columns)\n",
    "df = df.drop(columns=df.columns[0])\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_stack = np.empty((0, int(INTERVAL * SAMPLE_FREQ * N_COMPONENTS)))\n",
    "# print(data_stack)\n",
    "# print(data_stack.shape)\n",
    "for l in label:\n",
    "    for trial in train_number:\n",
    "        path = train_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:]) # drop raw columns\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "\n",
    "        if (df.equals(df.dropna()) == False):\n",
    "            print(\"Dropped NaN: \\n\", np.argwhere(np.isnan(df.values)))\n",
    "            df = df.dropna()  # Drop NaN (blank) datapts.\n",
    "\n",
    "        OFFSET = 1\n",
    "        while OFFSET < 7:\n",
    "            START = int(OFFSET * SAMPLE_FREQ)\n",
    "            END = int(START + SAMPLE_FREQ * INTERVAL)\n",
    "            OFFSET += 0.5\n",
    "\n",
    "            raw = df.iloc[START:END]  # Select by row\n",
    "            raw_vals = raw.values\n",
    "    #         print(np.argwhere(np.isnan(raw_vals)))\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, int(INTERVAL * SAMPLE_FREQ * N_COMPONENTS)))\n",
    "            data_stack = np.concatenate((data_stack, raw_vals), axis=0)\n",
    "#         print(data_stack.shape)\n",
    "df_stack = pd.DataFrame(data_stack)\n",
    "# print(df_stack.head())\n",
    "# num_rows=num_trials; num_cols=num_datapts\n",
    "print(\"data_stack shape: \", data_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(data_stack))) == 0)  # Should be empty\n",
    "\n",
    "# Labels\n",
    "train_labels = [1] * TRAIN_SAMPLES + [0] * TRAIN_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stack = np.empty((0, int(INTERVAL * SAMPLE_FREQ * N_COMPONENTS)))\n",
    "for l in label:\n",
    "    for trial in test_number:\n",
    "        path = test_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:]) # drop raw columns\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "        \n",
    "        if (df.equals(df.dropna()) == False):\n",
    "            print(\"Dropped NaN: \\n\", np.argwhere(np.isnan(df.values)))\n",
    "            df = df.dropna()  # Drop NaN (blank) datapts.\n",
    "\n",
    "        OFFSET = 1\n",
    "        while OFFSET < 7:\n",
    "            START = int(OFFSET * SAMPLE_FREQ)\n",
    "            END = int(START + SAMPLE_FREQ * INTERVAL)\n",
    "            OFFSET += 0.5\n",
    "\n",
    "            raw = df.iloc[START:END]  # Select by row\n",
    "            raw_vals = raw.values\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, int(INTERVAL * SAMPLE_FREQ * N_COMPONENTS)))\n",
    "            test_stack = np.concatenate((test_stack, raw_vals), axis=0)\n",
    "#             print(test_stack.shape)\n",
    "df_test = pd.DataFrame(test_stack)\n",
    "# print(df_stack.head())\n",
    "# num_rows=num_trials; num_cols=num_datapts\n",
    "print(\"test_stack shape: \", test_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(test_stack))) == 0)  # Should be empty\n",
    "\n",
    "# Labels\n",
    "test_labels = [1] * TEST_SAMPLES + [0] * TEST_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Clustering of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(df_columns)\n",
    "\n",
    "tsne_df = pd.DataFrame()\n",
    "\n",
    "# Plot\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:, 0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:, 1]\n",
    "# Labels\n",
    "y = [1] * NUM_SAMPLES[0] + [0] * NUM_SAMPLES[1]\n",
    "tsne_df['y'] = y\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=tsne_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground: Multiple t-SNEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10), constrained_layout=True)\n",
    "spec = gridspec.GridSpec(ncols=5, nrows=5, figure=fig)\n",
    "\n",
    "for niter in range(250, 1500, 250):\n",
    "    for perp in range(10, 55, 10):\n",
    "        # multiple t-SNEs\n",
    "        tsne = TSNE(n_components=2, verbose=1, perplexity=perp, n_iter=niter)\n",
    "        tsne_results = tsne.fit_transform(df_columns)\n",
    "        \n",
    "        tsne_df = pd.DataFrame()\n",
    "        \n",
    "        coord_prefix = 'tsne-2d-'\n",
    "        coord_desc = str(niter) + '-' + str(perp)\n",
    "        x_coord = coord_prefix + coord_desc + '-one'\n",
    "        y_coord = coord_prefix + coord_desc + '-two'\n",
    "        tsne_df[x_coord] = tsne_results[:, 0]\n",
    "        tsne_df[y_coord] = tsne_results[:, 1]\n",
    "\n",
    "        # Labels\n",
    "        y = [1] * NUM_SAMPLES[0] + [0] * NUM_SAMPLES[1]\n",
    "        tsne_df['y'] = y\n",
    "\n",
    "        niter_offset = int((niter-250)/250)\n",
    "        perp_offset = int((perp-10)/10)\n",
    "        fig.add_subplot(spec[niter_offset, perp_offset])\n",
    "        sns.scatterplot(\n",
    "            x=x_coord, y=y_coord,\n",
    "            hue=\"y\",\n",
    "            palette=sns.color_palette(\"hls\", 2),\n",
    "            data=tsne_df,\n",
    "            legend=\"full\",\n",
    "            alpha=0.8,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Clustering of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca_result = pca.fit_transform(df_columns)\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "print('Sum:', sum(pca.explained_variance_ratio_))\n",
    "## Explained variation per principal component: [0.1557712  0.11314638 0.08842925]\n",
    "\n",
    "# Labels\n",
    "y = [1] * NUM_TRAIN_SAMPLES[0] \\\n",
    "    + [2] * NUM_TEST_SAMPLES[0] \\\n",
    "    + [0] * NUM_TRAIN_SAMPLES[1] \\\n",
    "    + [3] * NUM_TEST_SAMPLES[1]\n",
    "\n",
    "# Plot: 3d\n",
    "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=pca_result[:,0], \n",
    "    ys=pca_result[:,1], \n",
    "    zs=pca_result[:,2], \n",
    "    c=y, \n",
    "    cmap='jet',\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.show()\n",
    "\n",
    "# Plot: 2d\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=pca_result[:,0], y=pca_result[:,1],\n",
    "    hue=y,\n",
    "    palette=sns.color_palette(\"hls\", 4),\n",
    "    legend=\"full\",\n",
    "    alpha=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Synchronized Events from Audio/EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO_\n",
      "#### ***********************************************************************************82 #### **********************************************************************69 #### ************************************35 \n",
      "\n",
      "STOP_\n",
      "#### ****************************************************************************75 #### ***************************************************************************************86 #### **********************************************45 \n",
      "\n",
      "data_stack shape:  (392, 102, 4)\n",
      "spects_stack shape:  (392, 4, 33, 39)\n",
      "confirm no NaN: True\n",
      "[186, 206]\n"
     ]
    }
   ],
   "source": [
    "def to_eeg_index(audio_index):\n",
    "    return int(audio_index / AUDIO_SAMPLE_FREQ * SAMPLE_FREQ)\n",
    "\n",
    "END = to_eeg_index(INTERVAL * AUDIO_SAMPLE_FREQ) # Produce training samples of uniform length.\n",
    "\n",
    "df_columns = np.empty((0, int(END * N_COMPONENTS)))\n",
    "data_stack = np.empty((0, END, N_COMPONENTS))\n",
    "spects_stack = np.empty((0, N_COMPONENTS, N_SPECT_FREQS, N_SPECT_TIMES)) # Spectrogram dimensions are particular.\n",
    "\n",
    "NUM_SAMPLES = []\n",
    "\n",
    "for l in label:\n",
    "    print(l)\n",
    "    event_cts = 0\n",
    "    for trial in train_number:\n",
    "        print('####', end=' ')\n",
    "        ### READ AUDIO DATA\n",
    "        audio_path = audio_root + audio_prefix + l + str(trial) + audio_suffix\n",
    "        _, samples = wavfile.read(audio_path)\n",
    "        envelope = np.abs(signal.hilbert(samples))\n",
    "        \n",
    "        ### GET AUDIO EVENTS\n",
    "        events = np.empty((0, 2))\n",
    "        in_event = False\n",
    "        new_event = np.zeros((1, 2))\n",
    "        hi_threshold_check = False\n",
    "        for s in range(len(samples)):\n",
    "            if (not in_event) and (envelope[s] >= AUDIO_EVENT_THRESHOLD_LO):\n",
    "                in_event = True\n",
    "                new_event[0][0] = s\n",
    "            elif (in_event) and (envelope[s] < AUDIO_EVENT_THRESHOLD_LO):\n",
    "                in_event = False\n",
    "                new_event[0][1] = s\n",
    "                event_length = new_event[0][1] - new_event[0][0]\n",
    "                if hi_threshold_check and event_length >= MIN_AUDIO_EVENT_LENGTH:\n",
    "#                     print(new_event[0][1] - new_event[0][0], end=' ') # Verbose Progress bar\n",
    "                    print('*', end='') # Simplified progress bar\n",
    "                    events = np.concatenate((events, new_event), axis=0)\n",
    "                    hi_threshold_check = False\n",
    "            elif (in_event) and (envelope[s] >= AUDIO_EVENT_THRESHOLD_HI):\n",
    "                hi_threshold_check = True\n",
    "\n",
    "        ### READ EEG DATA\n",
    "        cortical_path = train_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(cortical_path)\n",
    "        \n",
    "        \n",
    "        df = df.drop(columns=df.columns[25:])\n",
    "        df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "#         df = df.drop(columns=df.columns[21:])\n",
    "#         df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "\n",
    "        ### EXTRACT EEG EVENTS FROM AUDIO EVENTS (EACH EVENT IS A DATAPOINT)\n",
    "        cts = 0\n",
    "        for e in events:\n",
    "            cts += 1\n",
    "            event_cts += 1\n",
    "            \n",
    "            START = to_eeg_index(e[0])\n",
    "\n",
    "            raw = df.iloc[START:]\n",
    "            if (raw.equals(raw.dropna()) == False):\n",
    "                # print('Dropped NaN: %s%d, sample %d' %(l, trial, ct))\n",
    "                raw = raw.dropna()\n",
    "            raw = raw.iloc[:END]\n",
    "            raw_vals = raw.values\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, END, N_COMPONENTS)) # Split into N_COMPONENTS channels\n",
    "            data_stack = np.concatenate((data_stack, raw_vals), axis=0)\n",
    "            \n",
    "            ### GENERATE SPECTROGRAMS\n",
    "            spects = np.empty((0, N_SPECT_FREQS, N_SPECT_TIMES))\n",
    "            for ch in range(N_COMPONENTS):\n",
    "                ch_raw = raw_vals[0, :, ch]\n",
    "                ch_spect, freqs_spect, times_spect, image_spect = plt.specgram(\n",
    "                    ch_raw, NFFT=64, Fs=SAMPLE_FREQ, noverlap=63)\n",
    "                ch_spect = np.reshape(ch_spect, (1, N_SPECT_FREQS, N_SPECT_TIMES))\n",
    "                spects = np.concatenate((spects, ch_spect), axis=0) # Channels in one datapoint\n",
    "            \n",
    "            spects = np.reshape(spects, (1, N_COMPONENTS, N_SPECT_FREQS, N_SPECT_TIMES))\n",
    "            spects_stack = np.concatenate((spects_stack, spects), axis=0) # The tensor corresponding to this datapoint\n",
    "\n",
    "            ### FOR CLUSTERING PURPOSES\n",
    "            df_col = np.reshape(\n",
    "                raw_vals, (1, int(END * N_COMPONENTS))) # One vector of df_stack\n",
    "            df_columns = np.concatenate((df_columns, df_col), axis=0)\n",
    "                    \n",
    "            \n",
    "        print('*' + str(cts), end=' ') # Progress bar\n",
    "        \n",
    "    NUM_SAMPLES = NUM_SAMPLES + [event_cts]\n",
    "    print('\\n')\n",
    "\n",
    "df_stack = pd.DataFrame(df_columns) # Will only work when data is combined.\n",
    "# print(df_stack.head())\n",
    "print(\"data_stack shape: \", data_stack.shape)\n",
    "print(\"spects_stack shape: \", spects_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(data_stack))) == 0)  # Should be empty\n",
    "\n",
    "# Labels: 1=GO, 0=STOP\n",
    "data_labels = [1] * NUM_SAMPLES[0] + [0] * NUM_SAMPLES[1]\n",
    "print(NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 (33, 39)\n"
     ]
    }
   ],
   "source": [
    "go_mean, stop_mean = [], []\n",
    "for ch in range(N_COMPONENTS):\n",
    "    train_data_this_channel = train_data_ch_split[ch]\n",
    "    go_mean_ch = np.mean(train_data_this_channel[0:NUM_TRAIN_SAMPLES[0], :, :, :], axis=0)[0, :, :]\n",
    "    stop_mean_ch = np.mean(train_data_this_channel[NUM_TRAIN_SAMPLES[0]:, :, :, :], axis=0)[0, :, :]\n",
    "    go_mean = go_mean + [go_mean_ch]\n",
    "    stop_mean = stop_mean + [stop_mean_ch]\n",
    "print(len(go_mean), go_mean[0].shape)\n",
    "\n",
    "## plot on log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 4, 33, 39) (72, 4, 33, 39)\n",
      "4 (300, 1, 33, 39)\n",
      "4 (72, 1, 33, 39)\n",
      "(300, 39, 33, 4) (72, 39, 33, 4)\n",
      "(300,) (72,)\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN_SAMPLES = [150, 150]\n",
    "NUM_TEST_SAMPLES = [36, 36]\n",
    "\n",
    "### SINGLE CHANNEL\n",
    "# train_df = df_stack.iloc[np.r_[\n",
    "#     0:NUM_TRAIN_SAMPLES[0], \n",
    "#     NUM_SAMPLES[0]:NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]]]\n",
    "# test_df = df_stack.iloc[np.r_[\n",
    "#     NUM_TRAIN_SAMPLES[0]:NUM_SAMPLES[0],\n",
    "#     NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]:NUM_SAMPLES[0]+NUM_SAMPLES[1]]]\n",
    "# train_stack = train_df.values\n",
    "# test_stack = test_df.values\n",
    "\n",
    "### SPLIT CHANNEL\n",
    "# train_stack = data_stack[np.r_[\n",
    "#     0:NUM_TRAIN_SAMPLES[0], \n",
    "#     NUM_SAMPLES[0]:NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]], :, :]\n",
    "# test_stack = data_stack[np.r_[\n",
    "#     NUM_TRAIN_SAMPLES[0]:NUM_TRAIN_SAMPLES[0]+NUM_TEST_SAMPLES[0],\n",
    "#     NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]:NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]+NUM_TEST_SAMPLES[1]], :, :]\n",
    "# print(train_stack.shape, test_stack.shape)\n",
    "# train_data = np.split(train_stack, N_COMPONENTS, axis=2)\n",
    "# test_data = np.split(test_stack, N_COMPONENTS, axis=2)\n",
    "\n",
    "### SPECTROGRAM\n",
    "train_stack = spects_stack[np.r_[\n",
    "    0:NUM_TRAIN_SAMPLES[0],\n",
    "    NUM_SAMPLES[0]:NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]], :, :, :]\n",
    "test_stack = spects_stack[np.r_[\n",
    "    NUM_TRAIN_SAMPLES[0]:NUM_TRAIN_SAMPLES[0]+NUM_TEST_SAMPLES[0],\n",
    "    NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]:NUM_SAMPLES[0]+NUM_TRAIN_SAMPLES[1]+NUM_TEST_SAMPLES[1]], :, :, :]\n",
    "print(train_stack.shape, test_stack.shape)\n",
    "train_data_ch_split = np.split(train_stack, N_COMPONENTS, axis=1)\n",
    "test_data_ch_split = np.split(test_stack, N_COMPONENTS, axis=1)\n",
    "print(len(train_data_ch_split), train_data_ch_split[0].shape)\n",
    "print(len(test_data_ch_split), test_data_ch_split[0].shape)\n",
    "\n",
    "### CONVNET\n",
    "train_data_spect = np.swapaxes(train_stack, 1, 3)\n",
    "test_data_spect = np.swapaxes(test_stack, 1, 3)\n",
    "print(train_data_spect.shape, test_data_spect.shape)\n",
    "\n",
    "# Labels: 1=GO, 0=STOP\n",
    "train_labels = np.asarray([1] * NUM_TRAIN_SAMPLES[0] + [0] * NUM_TRAIN_SAMPLES[1])\n",
    "test_labels = np.asarray([1] * NUM_TEST_SAMPLES[0] + [0] * NUM_TEST_SAMPLES[1])\n",
    "\n",
    "# train_labels = np.concatenate(\n",
    "#     (np.tile([0, 1], (NUM_TRAIN_SAMPLES[0], 1)), # GO\n",
    "#      np.tile([1, 0], (NUM_TRAIN_SAMPLES[1], 1))) # STOP\n",
    "# )\n",
    "# test_labels = np.concatenate(\n",
    "#     (np.tile([0, 1], (NUM_TEST_SAMPLES[0], 1)), # GO\n",
    "#      np.tile([1, 0], (NUM_TEST_SAMPLES[1], 1))) # STOP\n",
    "# )\n",
    "print(train_labels.shape, test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Plot Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = audio_root + audio_prefix + label[1] + str(1) + audio_suffix\n",
    "print(audio_path)\n",
    "sample_rate, samples = wavfile.read(audio_path)\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(samples[:], )\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Events from Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_EVENT_THRESHOLD_LO = 1\n",
    "AUDIO_EVENT_THRESHOLD_HI = 1000\n",
    "AUDIO_PLT_LEFT, AUDIO_PLT_RIGHT = 0, len(envelope)\n",
    "envelope = np.abs(signal.hilbert(samples))\n",
    "threshold_lo = np.ones(len(envelope)) * AUDIO_EVENT_THRESHOLD_LO\n",
    "threshold_hi = np.ones(len(envelope)) * AUDIO_EVENT_THRESHOLD_HI\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.xlabel('Sample Coordinate'); plt.ylabel('Amplitude')\n",
    "plt.plot(samples[AUDIO_PLT_LEFT:AUDIO_PLT_RIGHT], label='raw')\n",
    "plt.plot(envelope[AUDIO_PLT_LEFT:AUDIO_PLT_RIGHT], label='envelope')\n",
    "plt.plot(threshold_lo[AUDIO_PLT_LEFT:AUDIO_PLT_RIGHT], label='threshold_lo')\n",
    "plt.plot(threshold_hi[AUDIO_PLT_LEFT:AUDIO_PLT_RIGHT], label='threshold_hi')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "events = np.empty((0, 2))\n",
    "in_event = False\n",
    "new_event = np.zeros((1, 2))\n",
    "hi_threshold_check = False\n",
    "\n",
    "for s in range(len(samples)):\n",
    "    if (not in_event) and (envelope[s] >= AUDIO_EVENT_THRESHOLD_LO):\n",
    "        in_event = True\n",
    "        new_event[0][0] = s\n",
    "    elif (in_event) and (envelope[s] < AUDIO_EVENT_THRESHOLD_LO):\n",
    "        in_event = False\n",
    "        new_event[0][1] = s\n",
    "        if hi_threshold_check:\n",
    "            events = np.concatenate((events, new_event), axis=0)\n",
    "            hi_threshold_check = False\n",
    "    elif (in_event) and (envelope[s] >= AUDIO_EVENT_THRESHOLD_HI):\n",
    "        hi_threshold_check = True\n",
    "\n",
    "print(events, len(events))\n",
    "\n",
    "for e in events:\n",
    "    print(e[1]-e[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference via KNN in PCA Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Sample into PCA Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_pca(raw_eeg, pca_components):\n",
    "    \"\"\"\n",
    "    Embeds RAW_EEG into the PCA representation space given by PCA_COMPONENTS\n",
    "    \"\"\"\n",
    "    return np.dot(pca_components, raw_eeg.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack_pca = embed_pca(train_stack, pca.components_)\n",
    "print(train_stack_pca.shape)\n",
    "test_stack_pca = embed_pca(test_stack, pca.components_)\n",
    "print(test_stack_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground: Embedding one sample into PCA Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure for obtaining one sample's representation in PCA space\n",
    "sample = data_stack[0,:]\n",
    "print(sample.shape)\n",
    "sample_rep = np.dot(pca_components, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground: Test Different k-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 51)\n",
    "scores_list = []\n",
    "TEST_TO_TRAIN_WEIGHT = 5\n",
    "total_stack_pca = np.concatenate(\n",
    "    (np.tile(test_stack_pca,\n",
    "             (TEST_TO_TRAIN_WEIGHT, 1)),\n",
    "     train_stack_pca))\n",
    "total_labels = np.concatenate(\n",
    "    (np.tile(test_labels,\n",
    "             (TEST_TO_TRAIN_WEIGHT)),\n",
    "     train_labels))\n",
    "print(total_stack_pca.shape)\n",
    "print(total_labels.shape)\n",
    "for k_val in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "    knn.fit(train_stack_pca, train_labels)\n",
    "    knn_predict = knn.predict(test_stack_pca)\n",
    "    scores_list.append(metrics.accuracy_score(test_labels, knn_predict))\n",
    "\n",
    "print('Maximum accuracy is %f' % (np.amax(scores_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot KNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=k_range, y=scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data to tf.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read into Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = 'csvc/'\n",
    "test_root = 'csvc/'\n",
    "train_number = range(1, 6)\n",
    "test_number = range(6, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stack = np.empty((0, int(INTERVAL * SAMPLE_FREQ), N_COMPONENTS))\n",
    "# print(data_stack.shape)\n",
    "\n",
    "for l in label:\n",
    "    for trial in train_number:\n",
    "        path = train_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:]) # drop raw columns\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "        \n",
    "#         print(df.shape)\n",
    "\n",
    "        if (df.equals(df.dropna()) == False):\n",
    "            print(\"Dropped NaN: \\n\", np.argwhere(np.isnan(df.values)))\n",
    "            df = df.dropna()  # Drop NaN (blank) datapts.\n",
    "\n",
    "        OFFSET = 1\n",
    "        while OFFSET < 7:\n",
    "            START = int(OFFSET * SAMPLE_FREQ)\n",
    "            END = int(START + SAMPLE_FREQ * INTERVAL)\n",
    "            OFFSET += 0.5\n",
    "\n",
    "            raw = df.iloc[START:END]  # Select by row\n",
    "            raw_vals = raw.values\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, int(INTERVAL * SAMPLE_FREQ), N_COMPONENTS))\n",
    "            data_stack = np.concatenate((data_stack, raw_vals), axis=0)\n",
    "#         print(data_stack.shape)\n",
    "        \n",
    "print(\"data_stack shape: \", data_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(data_stack))) == 0)  # Should be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stack = np.empty((0, int(INTERVAL * SAMPLE_FREQ), N_COMPONENTS))\n",
    "for l in label:\n",
    "    for trial in test_number:\n",
    "        path = test_root + prefix + l + str(trial) + suffix\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "#         df = df.drop(columns=df.columns[25:])\n",
    "#         df = df.drop(columns=df.columns[0:21])  # Only keep raw EEG data.\n",
    "\n",
    "        df = df.drop(columns=df.columns[21:]) # drop raw columns\n",
    "        df = df.drop(columns=df.columns[0]) # Keep only DTABG filtered components.\n",
    "        \n",
    "        if (df.equals(df.dropna()) == False):\n",
    "            print(\"Dropped NaN: \\n\", np.argwhere(np.isnan(df.values)))\n",
    "            df = df.dropna()  # Drop NaN (blank) datapts.\n",
    "\n",
    "        OFFSET = 1\n",
    "        while OFFSET < 7:\n",
    "            START = int(OFFSET * SAMPLE_FREQ)\n",
    "            END = int(START + SAMPLE_FREQ * INTERVAL)\n",
    "            OFFSET += 0.5\n",
    "\n",
    "            raw = df.iloc[START:END]  # Select by row\n",
    "            raw_vals = raw.values\n",
    "            raw_vals = np.reshape(\n",
    "                raw_vals, (1, int(INTERVAL * SAMPLE_FREQ), N_COMPONENTS))\n",
    "            test_stack = np.concatenate((test_stack, raw_vals), axis=0)\n",
    "#             print(test_stack.shape)\n",
    "# df_test = pd.DataFrame(test_stack)\n",
    "# print(df_stack.head())\n",
    "# num_rows=num_trials; num_cols=num_datapts\n",
    "print(\"test_stack shape: \", test_stack.shape)\n",
    "print(\"confirm no NaN:\", len(np.argwhere(np.isnan(test_stack))) == 0)  # Should be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "train_labels = np.concatenate(\n",
    "    (np.tile([0, 1], (NUM_TRAIN_SAMPLES[0], 1)), # GO\n",
    "     np.tile([1, 0], (NUM_TRAIN_SAMPLES[1], 1))) # STOP\n",
    ")\n",
    "test_labels = np.concatenate(\n",
    "    (np.tile([0, 1], (NUM_TEST_SAMPLES[0], 1)), # GO\n",
    "     np.tile([1, 0], (NUM_TEST_SAMPLES[1], 1))) # STOP\n",
    ")\n",
    "# [0 1]=GO, [1 0]=STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tf.data.Dataset from tensor slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DATASET_SIZE = NUM_TRAIN_SAMPLES[0] + NUM_TRAIN_SAMPLES[1]\n",
    "TRAIN_SIZE = int(FULL_DATASET_SIZE * 0.8)\n",
    "VALIDATION_SIZE = int(FULL_DATASET_SIZE * 0.2)\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "VALIDATION_BATCH_SIZE = 1\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_stack, train_labels)\n",
    ").shuffle(FULL_DATASET_SIZE)\n",
    "\n",
    "train_dataset = full_dataset.take(TRAIN_SIZE).batch(TRAIN_BATCH_SIZE)\n",
    "validation_dataset = full_dataset.skip(TRAIN_SIZE).take(VALIDATION_SIZE).batch(VALIDATION_BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_stack, test_labels))\n",
    "TEST_SHUFFLE_BUFFER = NUM_TEST_SAMPLES[0] + NUM_TEST_SAMPLES[1]\n",
    "TEST_BATCH_SIZE = 1\n",
    "test_dataset = test_dataset.shuffle(TEST_SHUFFLE_BUFFER).batch(TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset, validation_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Basic Convolutional Neural Network\n",
    "* doesn't generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (int(SAMPLE_FREQ * INTERVAL), N_COMPONENTS, 1)\n",
    "raw_shape = (2040, 1)\n",
    "inputs = keras.Input(shape=raw_shape)\n",
    "# A proposed architecture is to use recurrent first to \"summarize,\"\n",
    "    # No need for embedding layer in recurrent subnetwork?\n",
    "# then use convolutional to classify.\n",
    "\n",
    "# reshape\n",
    "reshape = layers.Reshape((int(SAMPLE_FREQ * INTERVAL), N_COMPONENTS, 1), input_shape=raw_shape)\n",
    "first_conv = layers.Conv2D(16, 3, activation='relu')\n",
    "first_pool = layers.MaxPool2D(pool_size=(2, 1))\n",
    "second_conv = layers.Conv2D(32, 3, activation='relu')\n",
    "second_pool = layers.MaxPool2D(pool_size=(2, 1))\n",
    "third_conv = layers.Conv2D(64, 3, activation='relu')\n",
    "flattener = layers.Flatten()\n",
    "first_dense = layers.Dense(64, activation='relu')\n",
    "second_dense = layers.Dense(16, activation='relu')\n",
    "third_dense = layers.Dense(2)\n",
    "\n",
    "outputs = third_dense(\n",
    "    second_dense(first_dense(\n",
    "        flattener(\n",
    "            third_conv(\n",
    "                second_pool(second_conv(\n",
    "                    first_pool(first_conv(reshape(inputs))))))))))\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='simple_conv')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Basic Recurrent Neural Network\n",
    "* doesn't work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (int(SAMPLE_FREQ * INTERVAL), N_COMPONENTS)\n",
    "raw_shape = (2040,1)\n",
    "inputs = keras.Input(shape=raw_shape)\n",
    "\n",
    "reshape = layers.Reshape(input_shape, input_shape=raw_shape)\n",
    "recurr_layer = layers.LSTM(64, dropout=0.1, recurrent_dropout=0.1)\n",
    "first_dense = layers.Dense(64, activation='sigmoid')\n",
    "result_dense = layers.Dense(2, activation='sigmoid')\n",
    "\n",
    "outputs = result_dense(\n",
    "        first_dense(\n",
    "            recurr_layer(reshape(inputs))))\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='simple_lstm')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Multi-Channel Recurrent-->Dense Neural Network\n",
    "* works ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_ch_input_shape = (END, 1)\n",
    "LSTM_REDUCE_DIM = 64\n",
    "\n",
    "channel_inputs, recurr_layers = [], []\n",
    "for ch in range(N_COMPONENTS):\n",
    "    channel_inputs = channel_inputs + [keras.Input(shape=sg_ch_input_shape)]\n",
    "    print('channel_inputs:', channel_inputs[ch].shape)\n",
    "    recurr_layers = recurr_layers + [layers.LSTM(LSTM_REDUCE_DIM)(channel_inputs[ch])]\n",
    "    print('recurr_layer:', recurr_layers[ch].shape)\n",
    "    \n",
    "recurr_outs = layers.concatenate(recurr_layers)\n",
    "first_dense = layers.Dense(64, activation='tanh')(recurr_outs)\n",
    "dropout = layers.Dropout(0.1)(first_dense)\n",
    "output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "model = keras.Model(inputs=channel_inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'multi-channel_recurrent.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram Convolutional Neural Network\n",
    "* doesn't work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spect_input_shape = (N_SPECT_TIMES, N_SPECT_FREQS, N_COMPONENTS)\n",
    "inputs = keras.Input(shape=spect_input_shape)\n",
    "\n",
    "first_conv = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "first_pool = layers.MaxPooling2D((2, 2))(first_conv)\n",
    "second_conv = layers.Conv2D(64, (3, 3), activation='relu')(first_pool)\n",
    "second_pool = layers.MaxPooling2D((2, 2))(second_conv)\n",
    "third_conv = layers.Conv2D(64, (3, 3), activation='relu')(second_pool)\n",
    "flattener = layers.Flatten()(third_conv)\n",
    "first_dense = layers.Dense(64, activation='relu')(flattener)\n",
    "output = layers.Dense(1)(first_dense)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split-Channel Recurrent-Convolutional Neural Network (SpecTransformerNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************# (None, 39, 33)\n",
      "*********************************# (None, 39, 33)\n",
      "*********************************# (None, 39, 33)\n",
      "*********************************# (None, 39, 33)\n",
      "(None, 39, 33, 4)\n"
     ]
    }
   ],
   "source": [
    "sg_ch_spectrogram_shape = (1, N_SPECT_FREQS, N_SPECT_TIMES)\n",
    "LSTM_IN_SHAPE = (N_SPECT_TIMES, 1)\n",
    "LSTM_OUT_DIM = N_SPECT_TIMES\n",
    "\n",
    "spects_inputs, recurr_combined = [], []\n",
    "for ch in range(N_COMPONENTS):\n",
    "    # spectrogram from each EEG channel (4 spectrograms)\n",
    "    spects_inputs = spects_inputs + [keras.Input(shape=sg_ch_spectrogram_shape)]\n",
    "    recurr_this_channel = []\n",
    "    for freq in range(N_SPECT_FREQS):\n",
    "        slice_freq = layers.Lambda(lambda x: x[:, 0, freq, :])(spects_inputs[ch]) # slice to (N_SPECT_TIMES,)\n",
    "        reshape_for_recurr = layers.Reshape(LSTM_IN_SHAPE)(slice_freq)\n",
    "        # multi-channel recurrent net (transformer?)\n",
    "        recurr_this_channel = recurr_this_channel + [layers.LSTM(LSTM_OUT_DIM)(reshape_for_recurr)]\n",
    "        print('*', end='') # progress bar\n",
    "    # concat recurrent layers\n",
    "    recurr_combined = recurr_combined + [layers.Lambda(\n",
    "        lambda x: tf.stack(x, axis=2))(\n",
    "            recurr_this_channel)]\n",
    "    print('#', recurr_combined[ch].shape)\n",
    "# feature image with 4 \"spatial channels\" (2d * 4)\n",
    "transformed_spect_combined = layers.Lambda(\n",
    "        lambda x: tf.stack(x, axis=3))(\n",
    "                recurr_combined)\n",
    "print(transformed_spect_combined.shape)\n",
    "# ConvNet\n",
    "first_conv = layers.Conv2D(16, (3, 3), activation='relu')(transformed_spect_combined)\n",
    "first_pool = layers.MaxPooling2D((2, 2))(first_conv)\n",
    "second_conv = layers.Conv2D(32, (3, 3), activation='relu')(first_pool)\n",
    "second_pool = layers.MaxPooling2D((2, 2))(second_conv)\n",
    "third_conv = layers.Conv2D(64, (3, 3), activation='relu')(second_pool)\n",
    "flatten = layers.Flatten()(third_conv)\n",
    "first_dense = layers.Dense(64, activation='relu')(flatten)\n",
    "output = layers.Dense(1)(first_dense)\n",
    "\n",
    "model = keras.Model(inputs=spects_inputs, outputs=output)\n",
    "# model.summary()\n",
    "# keras.utils.plot_model(model, 'split-channel_recurr_conv_net.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=10, verbose=1, validation_data=validation_dataset) # with tf.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Channel Recurrent\n",
    "history = model.fit(train_data, train_labels, batch_size=8, epochs=30, validation_split=0.2, verbose=1) # split channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SpectConvNet\n",
    "history = model.fit(train_data_spect, train_labels, batch_size=8, epochs=20, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.6990 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 35s 929ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "30/38 [======================>.......] - ETA: 9s - loss: 0.6932 - accuracy: 0.5167 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b77aafb6b682>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### SpectRecurConvNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_ch_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\think\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### SpectRecurConvNet\n",
    "history = model.fit(train_data_ch_split, train_labels, batch_size=8, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3c0d684842a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 264ms/step - loss: 0.6931 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data_ch_split, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = model.predict(test_data_ch_split)\n",
    "round_test_out = list(map(np.round, np.concatenate(test_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "sns.scatterplot(x=range(len(round_test_out)),\n",
    "                y=round_test_out,\n",
    "                hue=test_labels,\n",
    "                alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = 'models/'\n",
    "model_name = 'multi-channel_recurrent'\n",
    "model_suffix = '.h5'\n",
    "model_path = model_root + model_name + model_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "613.2px",
    "left": "43px",
    "top": "110.8px",
    "width": "259.79px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 378.17572800000005,
   "position": {
    "height": "398.898px",
    "left": "798.364px",
    "right": "20px",
    "top": "20px",
    "width": "583.352px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
